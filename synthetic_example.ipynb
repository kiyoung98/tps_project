{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df12d78-72c4-4b17-babc-2a7e3b1a4297",
   "metadata": {},
   "source": [
    "# Synthetic Example\n",
    "\n",
    "This notebook includes independent scripts for training a neural bias potential with GFlownets and evaluating the realisticity and diversity of our model on a synthetic system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d405a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f267c4bf",
   "metadata": {},
   "source": [
    "### System Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "save_dir = \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e57500",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "force = False\n",
    "dist_feat = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f5137",
   "metadata": {},
   "source": [
    "### Sampling Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b92b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "num_steps = 1000\n",
    "timestep = 0.01\n",
    "num_samples = 512\n",
    "temperature = 1200\n",
    "kB = 8.6173303e-5 \n",
    "kbT = kB * temperature\n",
    "std = np.sqrt(2 * kbT * timestep)\n",
    "normal = torch.distributions.Normal(0, std)\n",
    "start_position = torch.tensor([-1.118, 0], dtype=torch.float32).to(device)\n",
    "target_position = torch.tensor([1.118, 0], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff820a",
   "metadata": {},
   "source": [
    "### Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb47f64-9313-4394-9b62-cc35ae77b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_z_lr = 0.01\n",
    "policy_lr = 0.001\n",
    "batch_size = 1024\n",
    "num_rollouts = 1000\n",
    "buffer_size = 50000\n",
    "trains_per_rollout = 100\n",
    "start_temperature = 4800\n",
    "# start_temperature = 1200\n",
    "end_temperature = 1200\n",
    "kbTs = (\n",
    "    torch.linspace(start_temperature, end_temperature, num_rollouts) * kB\n",
    ")\n",
    "train_stds = torch.sqrt(2 * kbTs * timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83154f",
   "metadata": {},
   "source": [
    "### Synthetic System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7539c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def system(pos):\n",
    "    pos.requires_grad_(True)\n",
    "    x = pos[:, 0]\n",
    "    y = pos[:, 1]\n",
    "    term_1 = 4 * (1 - x**2 - y**2) ** 2\n",
    "    term_2 = 2 * (x**2 - 2) ** 2\n",
    "    term_3 = ((x + y) ** 2 - 1) ** 2\n",
    "    term_4 = ((x - y) ** 2 - 1) ** 2\n",
    "    potential = (term_1 + term_2 + term_3 + term_4 - 2.0) / 6.0\n",
    "    force = -torch.autograd.grad(potential.sum(), pos)[0]\n",
    "    return potential, force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f028e60",
   "metadata": {},
   "source": [
    "### Neural Bias Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralBias(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        if force:\n",
    "            self.output_dim = 2\n",
    "        else:\n",
    "            self.output_dim = 1\n",
    "\n",
    "        if dist_feat:\n",
    "            self.input_dim = 3\n",
    "        else:  \n",
    "            self.input_dim = 2\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, self.output_dim, bias=False),\n",
    "        )\n",
    "\n",
    "        self.log_z = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, pos):\n",
    "        if not force:\n",
    "            pos.requires_grad = True\n",
    "        if dist_feat:\n",
    "            dist = torch.norm(pos - target_position, dim=-1, keepdim=True)\n",
    "            pos_ = torch.cat([pos, dist], dim=-1)\n",
    "        else:\n",
    "            pos_ = pos\n",
    "\n",
    "        out = self.mlp(pos_.reshape(-1, self.input_dim))\n",
    "\n",
    "        if not force:\n",
    "            f = -torch.autograd.grad(\n",
    "                out.sum(), pos, create_graph=True, retain_graph=True\n",
    "            )[0]\n",
    "        else:\n",
    "            f = out.view(*pos.shape)\n",
    "\n",
    "        return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944c134",
   "metadata": {},
   "source": [
    "### TPS-GFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowNetAgent:\n",
    "    def __init__(self):\n",
    "        self.policy = NeuralBias()\n",
    "        self.replay = ReplayBuffer()\n",
    "\n",
    "    def sample(self, std, training=True):\n",
    "        positions = torch.zeros(\n",
    "            (num_samples, num_steps + 1, 2),\n",
    "            device=device,\n",
    "        )\n",
    "        actions = torch.zeros(\n",
    "            (num_samples, num_steps, 2),\n",
    "            device=device,\n",
    "        )\n",
    "        noises = torch.normal(\n",
    "            torch.zeros(\n",
    "                (num_samples, num_steps, 2),\n",
    "                device=device,\n",
    "            ),\n",
    "            torch.ones(\n",
    "                (num_samples, num_steps, 2),\n",
    "                device=device,\n",
    "            ),\n",
    "        )\n",
    "        potentials = torch.zeros((num_samples, num_steps + 1), device=device)\n",
    "\n",
    "        potential = system(start_position.unsqueeze(0))[0]\n",
    "\n",
    "        position = start_position.unsqueeze(0)\n",
    "        positions[:, 0] = position\n",
    "        potentials[:, 0] = potential\n",
    "\n",
    "\n",
    "        for s in range(num_steps):\n",
    "            noise = noises[:, s]\n",
    "            bias = self.policy(position.detach()).squeeze().detach()\n",
    "            # bias = torch.zeros_like(noise)\n",
    "            potential, force = system(position)\n",
    "            mean = position + force * timestep\n",
    "            position = position + (force + bias) * timestep + std * noise\n",
    "            positions[:, s + 1] = position\n",
    "            potentials[:, s + 1] = potential\n",
    "            actions[:, s] = position - mean\n",
    "\n",
    "        log_md_reward = normal.log_prob(actions.detach())\n",
    "        log_target_reward = (\n",
    "            -0.5\n",
    "            * torch.square((positions - target_position.view(1, 1, -1)) / std).mean(2)\n",
    "            / sigma\n",
    "        )\n",
    "        log_target_reward, last_idx = log_target_reward.max(1)\n",
    "        log_reward = log_md_reward.mean((1, 2)) + log_target_reward\n",
    "\n",
    "        if training:\n",
    "            self.replay.add((positions.detach(), actions.detach(), log_reward.detach()))\n",
    "\n",
    "        log = {\n",
    "            \"positions\": positions,\n",
    "            \"potentials\": potentials,\n",
    "            \"log_likelihood\": log_md_reward.sum(-1).mean(1),\n",
    "            \"last_idx\": last_idx,\n",
    "        }\n",
    "        return log\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [\n",
    "                {\"params\": [self.policy.log_z], \"lr\": log_z_lr},\n",
    "                {\"params\": self.policy.mlp.parameters(), \"lr\": policy_lr},\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        positions, actions, log_reward = self.replay.sample()\n",
    "\n",
    "        biases = self.policy(positions[:, :-1].detach())\n",
    "\n",
    "        log_z = self.policy.log_z\n",
    "        log_forward = normal.log_prob(actions-biases).mean((1, 2))\n",
    "\n",
    "        loss = (log_z + log_forward - log_reward).square().mean()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    \n",
    "    \n",
    "class ReplayBuffer:\n",
    "    def __init__(self):\n",
    "        self.positions = torch.zeros(\n",
    "            (buffer_size, num_steps + 1, 2),\n",
    "            device=device,\n",
    "        )\n",
    "        self.actions = torch.zeros(\n",
    "            (buffer_size, num_steps, 2), device=device\n",
    "        )\n",
    "        self.log_reward = torch.zeros(buffer_size, device=device)\n",
    "\n",
    "        self.idx = 0\n",
    "        self.buffer_size = buffer_size\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def add(self, data):\n",
    "        indices = torch.arange(self.idx, self.idx + self.num_samples) % self.buffer_size\n",
    "        self.idx += self.num_samples\n",
    "\n",
    "        self.positions[indices], self.actions[indices], self.log_reward[indices] = data\n",
    "\n",
    "    def sample(self):\n",
    "        indices = torch.randperm(min(self.idx, self.buffer_size))[: self.num_samples]\n",
    "        return self.positions[indices], self.actions[indices], self.log_reward[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c804d93",
   "metadata": {},
   "source": [
    "### Metrics and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca7f950-9ff7-499d-9466-a12dc6cafe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.plot_samples = 64\n",
    "\n",
    "    def log(self, positions, potentials, log_likelihood, last_idx):\n",
    "        dist, dist_std = self.expected_distance(positions, last_idx)\n",
    "        ll, ll_std = self.log_likelihood(log_likelihood)\n",
    "        thp, etp, efp, etp_std, efp_std = self.cv_metrics(positions, potentials, last_idx)\n",
    "        if thp > 0:\n",
    "            print(f\"Rollout: {rollout}, ED: {dist:.2f} (±{dist_std:.2f}), THP: {thp:.2f}, ETP: {etp:.2f} (±{etp_std:.2f}), LL: {ll:.2f} (±{ll_std:.2f}), EFP: {efp:.2f} (±{efp_std:.2f})\")\n",
    "        else:\n",
    "            print(f\"Rollout: {rollout}, ED: {dist:.2f} (±{dist_std:.2f}), THP: None, ETP: None, LL: {ll:.2f} (±{ll_std:.2f}), EFP: None\")\n",
    "\n",
    "    def expected_distance(self, positions, last_idx):\n",
    "        last_position = positions[torch.arange(len(positions)), last_idx]\n",
    "        dists = (last_position - target_position.unsqueeze(0)).square().mean((1))\n",
    "        return dists.mean().item(), dists.std().item()\n",
    "\n",
    "    def cv_metrics(self, positions, potentials, last_idx):\n",
    "        etps, efps, etp_idxs, efp_idxs = [], [], [], []\n",
    "        last_position = positions[torch.arange(len(positions)), last_idx]\n",
    "        hits = (last_position - target_position.unsqueeze(0)).square().sum(1).sqrt() < 0.5\n",
    "\n",
    "        for i, hit_idx in enumerate(hits):\n",
    "            if hit_idx:\n",
    "                etp, idx = potentials[i][: last_idx[i] + 1].max(0)\n",
    "                etps.append(etp)\n",
    "                etp_idxs.append(idx.item())\n",
    "\n",
    "                efp = potentials[i][last_idx[i]]\n",
    "                efps.append(efp)\n",
    "                efp_idxs.append(last_idx[i].item())\n",
    "\n",
    "        if len(etps) > 0:\n",
    "            etps = torch.tensor(etps)\n",
    "            efps = torch.tensor(efps)\n",
    "\n",
    "            etp = etps.mean().item()\n",
    "            efp = efps.mean().item()\n",
    "\n",
    "            etp_std = etps.std().item()\n",
    "            efp_std = efps.std().item()\n",
    "        else:\n",
    "            etp = None\n",
    "            efp = None\n",
    "\n",
    "            etp_std = None\n",
    "            efp_std = None\n",
    "            \n",
    "        thp = 100 * hits.sum() / len(hits)\n",
    "        return thp, etp, efp, etp_std, efp_std\n",
    "\n",
    "    def log_likelihood(self, log_likelihood):\n",
    "        return log_likelihood.mean().item(), log_likelihood.std().item()\n",
    "\n",
    "    def plot_paths(self, save_dir, rollout, positions, last_idx):\n",
    "        fig, ax = plt.subplots(figsize=(7, 7))\n",
    "        positions = positions[:self.plot_samples].detach().cpu().numpy()\n",
    "    \n",
    "        z_num = 100\n",
    "        circle_size = 1200\n",
    "        saddle_size = 2400\n",
    "\n",
    "        plt.xlim(-1.5, 1.5)\n",
    "        plt.ylim(-1.5, 1.5)\n",
    "        x = np.linspace(-1.5, 1.5, 400)\n",
    "        y = np.linspace(-1.5, 1.5, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        \n",
    "        term_1 = 4 * (1 - X**2 - Y**2) ** 2\n",
    "        term_2 = 2 * (X**2 - 2) ** 2\n",
    "        term_3 = ((X + Y) ** 2 - 1) ** 2\n",
    "        term_4 = ((X - Y) ** 2 - 1) ** 2\n",
    "        Z = (term_1 + term_2 + term_3 + term_4 - 2.0) / 6.0\n",
    "    \n",
    "        ax.contourf(X, Y, Z, levels=z_num, zorder=0, vmax=3)\n",
    "    \n",
    "        # Plot start and end positions\n",
    "        ax.scatter([start_position[0].item()], [start_position[1].item()], \n",
    "                   edgecolors='black', c='w', zorder=z_num, s=circle_size)\n",
    "        ax.scatter([target_position[0].item()], [target_position[1].item()], \n",
    "                   edgecolors='black', c='w', zorder=z_num, s=circle_size)\n",
    "    \n",
    "        # Plot saddle points (you may need to adjust these coordinates)\n",
    "        saddle_points = [(0, 1), (0, -1)]\n",
    "        for saddle in saddle_points:\n",
    "            ax.scatter(saddle[0], saddle[1], edgecolors='black', c='w', \n",
    "                       zorder=z_num, s=saddle_size, marker=\"*\")\n",
    "    \n",
    "        cm = plt.get_cmap('gist_rainbow')\n",
    "        \n",
    "        ax.set_prop_cycle(color=[cm(1. * i / len(positions)) for i in range(len(positions))])\n",
    "        \n",
    "        for i in range(len(positions)):\n",
    "            ax.plot(positions[i, :last_idx[i], 0], positions[i, :last_idx[i], 1], \n",
    "                    marker='o', linestyle='None', markersize=2, alpha=1., zorder=z_num-1)\n",
    "    \n",
    "        # Plot basic configs\n",
    "        ax.set_xlabel('x', fontsize=24, fontweight='medium')\n",
    "        ax.set_ylabel('y', fontsize=24, fontweight='medium')\n",
    "        ax.tick_params(left=False, right=False, labelleft=False, \n",
    "                       labelbottom=False, bottom=False)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "        plt.savefig(f\"{rollout}.png\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12956b8b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "agent = FlowNetAgent()\n",
    "logger = Logger()\n",
    "\n",
    "for rollout in range(num_rollouts):\n",
    "    num_samples = 512\n",
    "    log = agent.sample(train_stds[rollout])\n",
    "    logger.log(**log)\n",
    "\n",
    "    for _ in range(trains_per_rollout):\n",
    "        agent.train()\n",
    "    \n",
    "    if rollout%200 == 0 or rollout==num_rollouts-1:\n",
    "        logger.plot_paths(save_dir, rollout, log[\"positions\"], log[\"last_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed53b8f-bcd6-45d3-91f1-13a2c337aa4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
